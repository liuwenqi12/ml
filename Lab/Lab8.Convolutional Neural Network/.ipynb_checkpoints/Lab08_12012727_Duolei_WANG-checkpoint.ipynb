{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "path = './datasets'\n",
    "\n",
    "trainset = CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "testset = CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 32, 32, 3\n",
    "        self.proc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # 16, 16, 64\n",
    "        self.proc2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 8, 8, 128\n",
    "        self.proc3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        # 4, 4, 256\n",
    "        \n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Linear(4*4*256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )       \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.proc1(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = self.proc2(x)\n",
    "        # print(x.size())\n",
    "\n",
    "        x = self.proc3(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = x.view(-1, 4*4*256)\n",
    "\n",
    "        x = self.classfier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time as t\n",
    "# import numpy as np\n",
    "# ########### Write Your Code Here ###########\n",
    "# LEARNING_RATE = 0.01\n",
    "# device = torch.device('mps')\n",
    "# model = CNN().to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "# opt = torch.optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "# ############################################\n",
    "\n",
    "# res = []\n",
    "\n",
    "# Epochs = 500\n",
    "# for i in range(Epochs):\n",
    "#     last_time = t.time()\n",
    "#     for cnt, (x, y) in enumerate(trainloader):\n",
    "#         samples = x.to(device)\n",
    "#         print(samples.size())\n",
    "#         y = y.to(device)\n",
    "#         output = model(samples)\n",
    "        \n",
    "        \n",
    "#         loss = loss_fn(output, y.to(device))\n",
    "#         opt.zero_grad()\n",
    "        \n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         y_pred = torch.argmax(output, dim=1).to(device)        \n",
    "#         acc = (torch.argwhere(y_pred == y)).size(0)/y.size(0)\n",
    "#         res.append(acc)\n",
    "        \n",
    "    \n",
    "#     mean_acc = np.mean(res)\n",
    "#     res.clear()\n",
    "#     this_time = t.time()\n",
    "#     print(\"Epoch:{}/{}, step:{}, loss:{:.4f}, time:{:.2f}\".format(i + 1, Epochs, i + 1, loss.item(), this_time - last_time))\n",
    "#     print(\"acc:{:.4f}\".format(mean_acc))\n",
    "    \n",
    "    \n",
    "#     if((i + 1)%(Epochs/(Epochs/10)) == 0):\n",
    "#         torch.save(model.state_dict(), 'model' + str(model)[:3] + \"_\" + str(opt)[:7] + \"lr=\" + str(LEARNING_RATE) + \"_\" + str(i/(Epochs/100) + 1) + '.pth')\n",
    "#         print(str(opt)[:7])\n",
    "#         print(\"Checkpoint save!\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.UntypedStorage(): Storage device not recognized: mps",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Erics\\Desktop\\machine learning\\SUSTech-CS405-Machine-Learning-main\\SUSTech-CS405-Machine-Learning-main\\Lab\\Lab8.Convolutional Neural Network\\Lab08_12012727_Duolei_WANG.ipynb 单元格 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Erics/Desktop/machine%20learning/SUSTech-CS405-Machine-Learning-main/SUSTech-CS405-Machine-Learning-main/Lab/Lab8.Convolutional%20Neural%20Network/Lab08_12012727_Duolei_WANG.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m CNN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Erics/Desktop/machine%20learning/SUSTech-CS405-Machine-Learning-main/SUSTech-CS405-Machine-Learning-main/Lab/Lab8.Convolutional%20Neural%20Network/Lab08_12012727_Duolei_WANG.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m finalModel \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_ada\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Erics/Desktop/machine%20learning/SUSTech-CS405-Machine-Learning-main/SUSTech-CS405-Machine-Learning-main/Lab/Lab8.Convolutional%20Neural%20Network/Lab08_12012727_Duolei_WANG.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(finalModel \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m, map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Erics/Desktop/machine%20learning/SUSTech-CS405-Machine-Learning-main/SUSTech-CS405-Machine-Learning-main/Lab/Lab8.Convolutional%20Neural%20Network/Lab08_12012727_Duolei_WANG.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1015\u001b[0m                      map_location,\n\u001b[0;32m   1016\u001b[0m                      pickle_module,\n\u001b[0;32m   1017\u001b[0m                      overall_storage\u001b[39m=\u001b[39moverall_storage,\n\u001b[0;32m   1018\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmmap can only be used with files saved with \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1424\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1392\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   1394\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1366\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         storage\u001b[39m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1363\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1366\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1367\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1368\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1371\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1299\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrestore_location\u001b[39m(storage, location):\n\u001b[1;32m-> 1299\u001b[0m     \u001b[39mreturn\u001b[39;00m default_restore_location(storage, \u001b[39mstr\u001b[39;49m(map_location))\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    380\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 381\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    382\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    383\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\serialization.py:316\u001b[0m, in \u001b[0;36m_mps_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mps_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 316\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mmps()\n",
      "File \u001b[1;32mc:\\Users\\Erics\\anaconda3\\lib\\site-packages\\torch\\storage.py:141\u001b[0m, in \u001b[0;36m_StorageBase.mps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a MPS copy of this storage if it's not already on the MPS\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mUntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize(), device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mcopy_(\u001b[39mself\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.UntypedStorage(): Storage device not recognized: mps"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "finalModel = \"model_ada\"\n",
    "\n",
    "model.load_state_dict(torch.load(finalModel + \".pth\", map_location=torch.device(\"mps\")))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "\n",
    "y_pred = torch.tensor([], dtype=torch.int32)\n",
    "y_test = torch.tensor([], dtype=torch.int32)\n",
    "\n",
    "for data in testloader:\n",
    "    x, y = data\n",
    "    tmp = torch.argmax(model(x), dim=1)\n",
    "    y_pred = torch.cat((y_pred, tmp), dim=0)\n",
    "    y_test = torch.cat((y_test, y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1000\n",
      "           1       0.86      0.81      0.83      1000\n",
      "           2       0.66      0.57      0.62      1000\n",
      "           3       0.53      0.54      0.54      1000\n",
      "           4       0.67      0.66      0.67      1000\n",
      "           5       0.62      0.63      0.62      1000\n",
      "           6       0.77      0.79      0.78      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.83      0.82      0.82      1000\n",
      "           9       0.76      0.83      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "arr_pred = np.array(y_pred)\n",
    "arr_test = np.array(y_test)\n",
    "\n",
    "print(classification_report(arr_test, arr_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
